{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pL7631cghuZj"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from collections import deque\n",
    "from keras.layers import Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YGOv0yA8hy2f"
   },
   "outputs": [],
   "source": [
    "BOARD_ROWS = 7\n",
    "BOARD_COLS = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BfELOA6sh3PJ"
   },
   "outputs": [],
   "source": [
    "# 참고 https://www.secmem.org/blog/2020/02/08/snake-dqn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NnE6669eiIdt"
   },
   "outputs": [],
   "source": [
    "class Germ:\n",
    "  def __init__(self, alpha = 0.002, gamma = 0.95, epsilon = 0.1):\n",
    "    self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
    "    self.board[0, 0] = self.board[BOARD_COLS-1, BOARD_COLS-1] = -1\n",
    "    self.board[BOARD_ROWS-1, 0] = self.board[0, BOARD_COLS-1] = 1\n",
    "    # 우리가 1, 선공일 때를 나타냄\n",
    "    self.isEnd = False\n",
    "    self.playerSymbol = 1\n",
    "    self.alpha = alpha\n",
    "    self.gamma = gamma\n",
    "    self.epsilon = epsilon\n",
    "    self.batch_size = 64\n",
    "    self.min_replay_memory_size = 1000 # 얼마가 적당할지 잘 모르겠음.\n",
    "    self.target_update_freq = 100\n",
    "\n",
    "    self.model = self.build_model()\n",
    "    self.target_model = self.build_model()\n",
    "    self.target_model.set_weights(self.model.get_weights())\n",
    "    self.model.summary()\n",
    "\n",
    "    self.replay_memory_size = 5000\n",
    "    self.replay_memory = deque(maxlen=self.replay_memory_size)\n",
    "    self.target_update_counter = 0\n",
    "\n",
    "  def cantmove(self): # 더 이상 움직일 수 없을 때 남은 곳을 상대 말로 채운다.\n",
    "    self.isEnd = True\n",
    "    for i in range(BOARD_ROWS):\n",
    "      for j in range(BOARD_COLS):\n",
    "        if self.board[i, j] == 0:\n",
    "          self.board[i, j] = -self.playerSymbol\n",
    "    return None\n",
    "  \n",
    "  def winner(self): # 맵이 다 찼다면 점수를 반환한다.\n",
    "    if sum(map(sum, map(abs, self.board))) == BOARD_ROWS*BOARD_COLS:\n",
    "      self.isEnd = True\n",
    "      return sum(map(sum, self.board))\n",
    "    return None\n",
    "\n",
    "  def availableActions(self): # 가능한 행동들을 반환한다.\n",
    "    Actions = []\n",
    "    for i in range(BOARD_ROWS):\n",
    "        for j in range(BOARD_COLS):\n",
    "            if self.board[i, j] == self.playerSymbol:\n",
    "                for ii in range(-2,3):\n",
    "                    for jj in range(-2,3):\n",
    "                        if ii == 0 and jj == 0:\n",
    "                          continue\n",
    "                        if i + ii < 0 or i + ii >= BOARD_ROWS or j + jj < 0 or j + jj >= BOARD_COLS:\n",
    "                          continue\n",
    "                        if self.board[i + ii, j + jj] == 0:\n",
    "                          act = i\n",
    "                          act = act*BOARD_COLS + j\n",
    "                          act = act*BOARD_COLS + i + ii\n",
    "                          act = act*BOARD_COLS + j + jj\n",
    "                          Actions.append(act)\n",
    "    return Actions\n",
    "\n",
    "  def isAvailableAction(self, Action): # 가능한 행동인지?\n",
    "    position = np.zeros(4)\n",
    "    Action = int(Action)\n",
    "    for i in range(4):\n",
    "      position[3-i] = Action % BOARD_COLS\n",
    "      Action = Action // BOARD_COLS\n",
    "    position = [int(i) for i in position]\n",
    "    return self.board[position[0]][position[1]]==self.playerSymbol and self.board[position[2]][position[3]]==0\n",
    "\n",
    "  def updateState(self, Action): # 현재 상태에서 특정 행동을 한 다음 상태로 업데이트 한다.\n",
    "      position = np.zeros(4)\n",
    "      for i in range(4):\n",
    "        position[3-i] = Action % BOARD_COLS\n",
    "        Action = Action // BOARD_COLS\n",
    "      position = [int(i) for i in position]\n",
    "      #print(Action, position)\n",
    "      ii = position[2] - position[0]\n",
    "      jj = position[3] - position[1]\n",
    "      if max(abs(ii), abs(jj)) == 2:\n",
    "          self.board[position[0:2]] = 0\n",
    "      \n",
    "      dx1 = [-1, -1, -1, 0, 0, 1, 1, 1]\n",
    "      dy1 = [-1, 0, 1, -1, 1, -1, 0, 1]\n",
    "      i, j = position[2:4]\n",
    "      self.board[i, j] = self.playerSymbol\n",
    "      for ii, jj in zip(dx1, dy1):\n",
    "          if i + ii < 0 or i + ii >= BOARD_ROWS or j + jj < 0 or j + jj >= BOARD_COLS:\n",
    "              continue\n",
    "          if self.board[i + ii, j + jj] == -self.playerSymbol:\n",
    "              self.board[i + ii, j + jj] = self.playerSymbol\n",
    "          \n",
    "      # switch to another player\n",
    "      self.playerSymbol = -self.playerSymbol\n",
    "\n",
    "  def reset(self): # 리셋.\n",
    "      self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
    "      self.board[0, 0] = self.board[BOARD_ROWS-1, BOARD_COLS-1] = 1\n",
    "      self.board[BOARD_ROWS-1, 0] = self.board[0, BOARD_COLS-1] = -1\n",
    "      self.boardHash = None\n",
    "      self.isEnd = False\n",
    "      self.playerSymbol = 1\n",
    "    \n",
    "  def test(self):\n",
    "    while not self.isEnd:\n",
    "      avac = availableActions()\n",
    "      if not avac:\n",
    "        self.cantmove()\n",
    "      else:\n",
    "        state = self.board\n",
    "        state = np.float32(state)\n",
    "        q_vals = self.p1.model.predict(state)[0,0,:]\n",
    "        opt_action = 0\n",
    "        for action in self.availableActions:\n",
    "          if opt_action == 0:\n",
    "            opt_action = action\n",
    "          elif q_vals[opt_action]<q_vals[action]:\n",
    "            opt_action = action\n",
    "        self.updateState(opt_action)\n",
    "      self.showBoard()\n",
    "      win = self.winner()\n",
    "      if win is not None:\n",
    "        if win > 0:\n",
    "          print(self.p1.name, \"wins!\")\n",
    "        else:\n",
    "          print(self.p2.name, \"wins!\")\n",
    "        self.reset()\n",
    "        break\n",
    "      \n",
    "      else:\n",
    "        avac = availableActions()\n",
    "        if not avac:\n",
    "          self.cantmove()\n",
    "        else:\n",
    "          state = self.board\n",
    "          state = np.float32(state)\n",
    "          q_vals = self.p2.model.predict(state)[-1]\n",
    "          opt_action == 0\n",
    "          for action in self.availableActions:\n",
    "            if opt_action == 0:\n",
    "              opt_action = action\n",
    "            elif q_vals[opt_action]<q_vals[action]:\n",
    "              opt_action = action\n",
    "          self.updateState(opt_action)\n",
    "        self.showBoard()\n",
    "        win = self.winner()\n",
    "        if win is not None:\n",
    "          if win > 0:\n",
    "            print(self.p2.name, \"wins!\")\n",
    "          else:\n",
    "            print(self.p1.name, \"wins!\")\n",
    "          print()\n",
    "          self.reset()\n",
    "          break\n",
    "        \n",
    "  def showBoard(self):\n",
    "    # p1: o  p2: x\n",
    "        for i in range(0, BOARD_ROWS):\n",
    "            print('------------------------------')\n",
    "            out = '| '\n",
    "            for j in range(0, BOARD_COLS):\n",
    "                if self.board[i, j] == 1:\n",
    "                    token = 'o'\n",
    "                if self.board[i, j] == -1:\n",
    "                    token = 'x'\n",
    "                if self.board[i, j] == 0:\n",
    "                    token = ' '\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('------------------------------')  \n",
    "\n",
    "  def build_model(self): # DQN 모델을 생성한다.\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), padding = 'valid', input_shape=(7, 7, 1), activation='relu'))\n",
    "    model.add(Conv2D(16, (3, 3), padding = 'valid', input_shape=(5, 5, 1), activation='relu'))\n",
    "    model.add(Conv2D(16, (3, 3), padding = 'valid', input_shape=(3, 3, 1), activation='relu'))\n",
    "    model.add(Dense(64 * BOARD_COLS * BOARD_COLS, activation='relu'))\n",
    "    model.add(Dense(BOARD_COLS**4, activation='relu'))\n",
    "    model.add(Reshape((BOARD_ROWS**4,)))\n",
    "    model.compile(loss='mse', optimizer=Adam(lr=self.alpha))\n",
    "    return model\n",
    "\n",
    "  def update_replay_memory(self, current_state, action, reward, next_state, done): # 리플레이 메모리에 상황을 저장한다.\n",
    "    self.replay_memory.append((current_state, action, reward, next_state, done))\n",
    "\n",
    "  def get_q_values(self, x): # 현재 상태에서 할 행동들의 q_value를 반환, x는 board에 대응됨.\n",
    "    return self.model.predict(x.reshape(1,BOARD_ROWS, BOARD_COLS, 1))\n",
    "\n",
    "  def getAction(self, state, epsilon):\n",
    "    if np.random.rand() <= epsilon:\n",
    "       # 무작위 행동 반환\n",
    "      avac_size = len(self.availableActions())\n",
    "      return self.availableActions()[random.randrange(avac_size)]\n",
    "    else:\n",
    "       # 모델로부터 행동 산출\n",
    "      state = np.float32(state*self.playerSymbol)\n",
    "      q_values = self.model.predict(state.reshape(1,BOARD_ROWS,BOARD_COLS,1))\n",
    "      return np.argmax(q_values)\n",
    "\n",
    "  def epsbyepi(self, episode):\n",
    "    return max(self.epsilon, 1 - 1/(1+np.exp(-episode/2500+6)))\n",
    "\n",
    "  def play(self, episode):\n",
    "    prev_state = np.zeros((BOARD_ROWS,BOARD_COLS))\n",
    "    self.reset()\n",
    "    while not self.isEnd:\n",
    "      #self.showBoard()\n",
    "      avac = self.availableActions()\n",
    "      dora = False\n",
    "      if not avac:\n",
    "        self.cantmove()\n",
    "      else:\n",
    "        action = self.getAction(self.board, self.epsbyepi(episode))\n",
    "        state = self.board * self.playerSymbol\n",
    "        if self.isAvailableAction(action):\n",
    "          self.updateState(action)\n",
    "          win = self.winner()\n",
    "          if win is None:\n",
    "            reward = 0\n",
    "          else:\n",
    "            reward = win * self.playerSymbol\n",
    "            dora = True\n",
    "        else:\n",
    "          self.isEnd = True\n",
    "          reward = -100\n",
    "      if self.isEnd and dora:\n",
    "        self.update_replay_memory(prev_state[0], prev_state[1], -reward, prev_state[2], False)\n",
    "      prev_state = (state, action, self.board)\n",
    "      self.update_replay_memory(state, action, reward, self.board, self.isEnd)\n",
    "      #print(action)\n",
    "      #print(state)\n",
    "      #print(win, reward, self.isEnd, dora, self.playerSymbol)\n",
    "    \n",
    "\n",
    "  def train(self):\n",
    "    if len(self.replay_memory)<self.min_replay_memory_size: # 충분히 모이지 않으면 학습하지 않는다.\n",
    "      return\n",
    "    \n",
    "    samples = random.sample(self.replay_memory, self.batch_size)\n",
    "    current_input = np.stack([sample[0] for sample in samples]) # current_state들의 array\n",
    "    current_q_values = self.model.predict(current_input.reshape(len(current_input),BOARD_ROWS, BOARD_COLS,1))\n",
    "    next_input = np.stack([sample[3] for sample in samples])\n",
    "    next_q_values = self.target_model.predict(next_input.reshape(len(next_input),BOARD_ROWS, BOARD_COLS,1))\n",
    "    \n",
    "    for i, (current_state, action, reward, _, done) in enumerate(samples):\n",
    "      if done:\n",
    "        next_q_value = reward\n",
    "      else:\n",
    "        next_q_value = reward + self.gamma * np.max(next_q_values[i])\n",
    "      current_q_values[i, action] = next_q_value\n",
    "    current_input = current_input.reshape((len(current_input),BOARD_ROWS,BOARD_COLS,1))\n",
    "    hist = self.model.fit(current_input, current_q_values, batch_size=self.batch_size, verbose=1, shuffle=False)\n",
    "    loss = hist.history['loss'][0]\n",
    "    return loss\n",
    "\n",
    "  def increase_target_update_counter(self): # target_model에 model을 업데이트한다. 그걸 세는 함수.\n",
    "    self.target_update_counter += 1\n",
    "    if self.target_update_counter >= self.target_update_freq:\n",
    "      self.target_model.set_weights(self.model.get_weights())\n",
    "      self.target_update_counter = 0\n",
    "\n",
    "  def save(self, model_filepath, target_model_filepath):\n",
    "    self.model.save(model_filepath)\n",
    "    self.target_model.save(target_model_filepath)\n",
    "\n",
    "  def load(self, model_filepath, target_model_filepath):\n",
    "    self.model = keras.models.load_model(model_filepath)\n",
    "    self.target_model = keras.models.load_model(target_model_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "zUHe5aWxyHpw",
    "outputId": "38720275-9766-491e-8443-01da551b0c08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 5, 5, 16)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 3, 3, 16)          2320      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 1, 16)          2320      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1, 1, 3136)        53312     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1, 1, 2401)        7531937   \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 2401)              0         \n",
      "=================================================================\n",
      "Total params: 7,590,049\n",
      "Trainable params: 7,590,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dora = Germ()\n",
    "dora.build_model()\n",
    "# dora.load(뭐시기)\n",
    "episode = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZOdypu2ZyxQM",
    "outputId": "8f90fd86-c705-4c3a-a6f4-81627aa194d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.2940e-07\n",
      "round 2000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7574e-07\n",
      "round 3000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.3327e-07\n",
      "round 4000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1953\n",
      "round 5000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0651\n",
      "round 6000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1302\n",
      "round 7000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0651\n",
      "round 8000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2604\n",
      "round 9000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1953\n",
      "round 10000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1953\n",
      "round 11000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3905\n",
      "round 12000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8462\n",
      "round 13000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5207\n",
      "round 14000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2366\n",
      "round 15000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4319\n",
      "round 16000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1477\n",
      "round 17000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2779\n",
      "round 18000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.0826\n",
      "round 19000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9287\n",
      "round 20000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3191\n",
      "round 21000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.2540\n",
      "round 22000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3192\n",
      "round 23000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6445\n",
      "round 24000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7747\n",
      "round 25000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9048\n",
      "round 26000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6446\n",
      "round 27000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7985\n",
      "round 28000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8636\n",
      "round 29000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7986\n",
      "round 30000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7985\n",
      "round 31000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5795\n",
      "round 32000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.0351\n",
      "round 33000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9049\n",
      "round 34000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9049\n",
      "round 35000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3842\n",
      "round 36000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5795\n",
      "round 37000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9049\n",
      "round 38000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8398\n",
      "round 39000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8399\n",
      "round 40000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7748\n",
      "round 41000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1002\n",
      "round 42000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7097\n",
      "round 43000\n",
      "1/1 [==============================] - 0s 970us/step - loss: 3.5144\n",
      "round 44000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7097\n",
      "round 45000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8399\n",
      "round 46000\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 3.5795\n",
      "round 47000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8398\n",
      "round 48000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5795\n",
      "round 49000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7096\n",
      "round 50000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9050\n",
      "round 51000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5144\n",
      "round 52000\n",
      "1/1 [==============================] - 0s 966us/step - loss: 3.8398\n",
      "round 53000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5795\n",
      "round 54000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5796\n",
      "round 55000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6447\n",
      "round 56000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5795\n",
      "round 57000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7097\n",
      "round 58000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9939\n",
      "round 59000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9287\n",
      "round 60000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0588\n",
      "round 61000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7986\n",
      "round 62000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5795\n",
      "round 63000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5796\n",
      "round 64000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5795\n",
      "round 65000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8398\n",
      "round 66000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6446\n",
      "round 67000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7748\n",
      "round 68000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.9048\n",
      "round 69000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9050\n",
      "round 70000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9287\n",
      "round 71000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4732\n",
      "round 72000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7334\n",
      "round 73000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3192\n",
      "round 74000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4494\n",
      "round 75000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7097\n",
      "round 76000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7096\n",
      "round 77000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6446\n",
      "round 78000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7097\n",
      "round 79000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9049\n",
      "round 80000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1239\n",
      "round 81000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.3192\n",
      "round 82000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7572\n",
      "round 83000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1891\n",
      "round 84000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8636\n",
      "round 85000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9287\n",
      "round 86000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.8399\n",
      "round 87000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9049\n",
      "round 88000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7748\n",
      "round 89000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7096\n",
      "round 90000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0589\n",
      "round 91000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7334\n",
      "round 92000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1889\n",
      "round 93000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1240\n",
      "round 94000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0589\n",
      "round 95000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9699\n",
      "round 96000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7096\n",
      "round 97000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9048\n",
      "round 98000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.7747\n",
      "round 99000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6444\n"
     ]
    }
   ],
   "source": [
    "for i in range(100000):\n",
    "  dora.play(episode)\n",
    "  episode += 1\n",
    "  dora.increase_target_update_counter()\n",
    "  if i%1000==0 and i>0:\n",
    "    print(\"round\",i)\n",
    "    dora.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "kseW_GLhGWeq",
    "outputId": "e2b028c4-8e75-4ed4-8f9d-4eb0815724bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./model/model100000/assets\n",
      "INFO:tensorflow:Assets written to: ./model/target100000/assets\n"
     ]
    }
   ],
   "source": [
    "dora.save(\"./model/model100000\",\"./model/target100000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "colab_type": "code",
    "id": "bNLCvesHXCfm",
    "outputId": "1c62b42b-4b74-476d-d613-e2cd592755de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom google.colab import files\\nfiles.download('model10000')\\nfiles.download('target10000')\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from google.colab import files\n",
    "files.download('model10000')\n",
    "files.download('target10000')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zCndvt5ZXZYA"
   },
   "outputs": [],
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 5, 5, 16)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 3, 3, 16)          2320      \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 1, 1, 16)          2320      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1, 1, 3136)        53312     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1, 1, 2401)        7531937   \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 2401)              0         \n",
      "=================================================================\n",
      "Total params: 7,590,049\n",
      "Trainable params: 7,590,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dora = Germ()\n",
    "dora.load(\"./model/model100000\",\"./model/target100000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self,isHuman,playerSymbol):\n",
    "        self.isHuman=isHuman\n",
    "        self.model = self.build_model()\n",
    "        self.playerSymbol = playerSymbol\n",
    "    \n",
    "    def build_model(self): # DQN 모델을 생성한다.\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(16, (3, 3), padding = 'valid', input_shape=(7, 7, 1), activation='relu'))\n",
    "        model.add(Conv2D(16, (3, 3), padding = 'valid', input_shape=(5, 5, 1), activation='relu'))\n",
    "        model.add(Conv2D(16, (3, 3), padding = 'valid', input_shape=(3, 3, 1), activation='relu'))\n",
    "        model.add(Dense(64 * BOARD_COLS * BOARD_COLS, activation='relu'))\n",
    "        model.add(Dense(BOARD_COLS**4, activation='relu'))\n",
    "        model.add(Reshape((BOARD_ROWS**4,)))\n",
    "        #model.compile(loss='mse', optimizer=Adam(lr=self.alpha))\n",
    "        return model\n",
    "\n",
    "    def availableActions(self,state): # 가능한 행동들을 반환한다.\n",
    "        Actions = []\n",
    "        for i in range(BOARD_ROWS):\n",
    "            for j in range(BOARD_COLS):\n",
    "                if state[i, j] == self.playerSymbol:\n",
    "                    for ii in range(-2,3):\n",
    "                        for jj in range(-2,3):\n",
    "                            if ii == 0 and jj == 0:\n",
    "                                continue\n",
    "                            if i + ii < 0 or i + ii >= BOARD_ROWS or j + jj < 0 or j + jj >= BOARD_COLS:\n",
    "                                continue\n",
    "                            if state[i + ii, j + jj] == 0:\n",
    "                                act = i\n",
    "                                act = act*BOARD_COLS + j\n",
    "                                act = act*BOARD_COLS + i + ii\n",
    "                                act = act*BOARD_COLS + j + jj\n",
    "                                Actions.append(act)\n",
    "        return Actions    \n",
    "    \n",
    "    def getAction(self,state):\n",
    "        if self.isHuman:\n",
    "            print(\"original row, col, target row, col\")\n",
    "            ro = int(input())\n",
    "            co = int(input())\n",
    "            rt = int(input())\n",
    "            ct = int(input())\n",
    "            if not ro>=0 and ro<7 and co>=0 and co<7 and rt>=0 and rt<7 and ct>=0 and ct<7:\n",
    "                return None\n",
    "            return ro*7*7*7+co*7*7+rt*7+ct\n",
    "        else:\n",
    "            q_val = self.model.predict(state.reshape(1,BOARD_ROWS, BOARD_COLS, 1))\n",
    "            avac = self.availableActions(state)\n",
    "            avq = np.zeros(len(avac))\n",
    "            for i,a in enumerate(avac):\n",
    "                avq[i]=a\n",
    "            return avq[np.argmax(avq)]\n",
    "\n",
    "    def load(self, model_filepath):\n",
    "        self.model = keras.models.load_model(model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charm.ipynb          Lunch_outside.ipynb  \u001b[34mmodel\u001b[m\u001b[m/\r\n",
      "Charm_Cracker.ipynb  README.md\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class contest:\n",
    "    def __init__(self,p1,p2):\n",
    "        self.board = np.zeros((7,7))\n",
    "        self.board[0,6]=self.board[6,0]=1\n",
    "        self.board[0,0]=self.board[6,6]=-1\n",
    "        self.p1=p1\n",
    "        self.p2=p2\n",
    "        self.isEnd = False\n",
    "        \n",
    "    \n",
    "        \n",
    "    def updateState(self, Action, p): # 현재 상태에서 특정 행동을 한 다음 상태로 업데이트 한다.\n",
    "        dora = Action\n",
    "        position = np.zeros(4)\n",
    "        for i in range(4):\n",
    "            position[3-i] = Action % BOARD_COLS\n",
    "            Action = Action // BOARD_COLS\n",
    "        position = [int(i) for i in position]\n",
    "        ii = position[2] - position[0]\n",
    "        jj = position[3] - position[1]\n",
    "#         print(\"haha\")\n",
    "#         print(position)\n",
    "#         print(ii,jj)\n",
    "#         self.showBoard()\n",
    "#         print(self.board[position[0:2]])\n",
    "        if max(abs(ii), abs(jj)) == 2:\n",
    "            self.board[position[0],position[1]] = 0\n",
    "      \n",
    "        dx1 = [-1, -1, -1, 0, 0, 1, 1, 1]\n",
    "        dy1 = [-1, 0, 1, -1, 1, -1, 0, 1]\n",
    "        i, j = position[2:4]\n",
    "#         print(\"yay\")\n",
    "#         print(i,j)\n",
    "#         self.showBoard()\n",
    "        self.board[i, j] = p.playerSymbol\n",
    "        for ii, jj in zip(dx1, dy1):\n",
    "            if i + ii < 0 or i + ii >= BOARD_ROWS or j + jj < 0 or j + jj >= BOARD_COLS:\n",
    "                continue\n",
    "            if self.board[i + ii, j + jj] == -p.playerSymbol:\n",
    "                self.board[i + ii, j + jj] = p.playerSymbol\n",
    "        print(\"(\",dora//(7**3),\" \",(dora//(7**2))%7,\" \",(dora//7)%7,\" \",dora%7,\")\")\n",
    "                \n",
    "    def winner(self): # 맵이 다 찼다면 점수를 반환한다.\n",
    "        if sum(map(sum, map(abs, self.board))) == BOARD_ROWS*BOARD_COLS:\n",
    "            self.isEnd = True\n",
    "            return sum(map(sum, self.board))\n",
    "        return None\n",
    "\n",
    "    def showBoard(self):\n",
    "    # p1: o  p2: x\n",
    "        for i in range(0, BOARD_ROWS):\n",
    "            print('------------------------------')\n",
    "            out = '| '\n",
    "            for j in range(0, BOARD_COLS):\n",
    "                if self.board[i, j] == 1:\n",
    "                    token = 'o'\n",
    "                if self.board[i, j] == -1:\n",
    "                    token = 'x'\n",
    "                if self.board[i, j] == 0:\n",
    "                    token = ' '\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('------------------------------')  \n",
    "        \n",
    "    def cantmove(self,p): # 더 이상 움직일 수 없을 때 남은 곳을 상대 말로 채운다.\n",
    "        self.isEnd = True\n",
    "        for i in range(BOARD_ROWS):\n",
    "          for j in range(BOARD_COLS):\n",
    "            if self.board[i, j] == 0:\n",
    "              self.board[i, j] = -p.playerSymbol\n",
    "        return None\n",
    "        \n",
    "    def start(self): # 게임을 시작한다.\n",
    "        self.showBoard()\n",
    "        while not self.isEnd:\n",
    "            action1 = self.p1.getAction(self.board)\n",
    "            if action1 is None:\n",
    "                self.cantmove(self.p1)\n",
    "                break\n",
    "            self.updateState(action1,self.p1)\n",
    "            self.showBoard()\n",
    "            win=self.winner()\n",
    "            if win:\n",
    "                self.isEnd = True\n",
    "                print(\"player\", int((3-np.sign(win))/2), \"win\")\n",
    "                break\n",
    "            action2 = self.p2.getAction(self.board)\n",
    "            if action2 is None:\n",
    "                self.cantmove(self.p2)\n",
    "                break\n",
    "            self.updateState(action2,self.p2)\n",
    "            self.showBoard()\n",
    "            win=self.winner()\n",
    "            if win:\n",
    "                self.isEnd = True\n",
    "                print(\"player\", int((3-np.sign(win))/2), \"win\")\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| x |   |   |   |   |   | o | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "| o |   |   |   |   |   | x | \n",
      "------------------------------\n",
      "original row, col, target row, col\n",
      "0\n",
      "6\n",
      "1\n",
      "5\n",
      "( 0   6   1   5 )\n",
      "------------------------------\n",
      "| x |   |   |   |   |   | o | \n",
      "------------------------------\n",
      "|   |   |   |   |   | o |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "| o |   |   |   |   |   | x | \n",
      "------------------------------\n",
      "( 6.0   6.0   6.0   5.0 )\n",
      "------------------------------\n",
      "| x |   |   |   |   |   | o | \n",
      "------------------------------\n",
      "|   |   |   |   |   | o |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "| o |   |   |   |   | x | x | \n",
      "------------------------------\n",
      "original row, col, target row, col\n",
      "1\n",
      "5\n",
      "2\n",
      "4\n",
      "( 1   5   2   4 )\n",
      "------------------------------\n",
      "| x |   |   |   |   |   | o | \n",
      "------------------------------\n",
      "|   |   |   |   |   | o |   | \n",
      "------------------------------\n",
      "|   |   |   |   | o |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "| o |   |   |   |   | x | x | \n",
      "------------------------------\n",
      "( 6.0   6.0   6.0   4.0 )\n",
      "------------------------------\n",
      "| x |   |   |   |   |   | o | \n",
      "------------------------------\n",
      "|   |   |   |   |   | o |   | \n",
      "------------------------------\n",
      "|   |   |   |   | o |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "| o |   |   |   | x | x |   | \n",
      "------------------------------\n",
      "original row, col, target row, col\n",
      "2\n",
      "4\n",
      "1\n",
      "3\n",
      "( 2   4   1   3 )\n",
      "------------------------------\n",
      "| x |   |   |   |   |   | o | \n",
      "------------------------------\n",
      "|   |   |   | o |   | o |   | \n",
      "------------------------------\n",
      "|   |   |   |   | o |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "| o |   |   |   | x | x |   | \n",
      "------------------------------\n",
      "( 6.0   5.0   6.0   6.0 )\n",
      "------------------------------\n",
      "| x |   |   |   |   |   | o | \n",
      "------------------------------\n",
      "|   |   |   | o |   | o |   | \n",
      "------------------------------\n",
      "|   |   |   |   | o |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "| o |   |   |   | x | x | x | \n",
      "------------------------------\n",
      "original row, col, target row, col\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "( 1   3   1   1 )\n",
      "------------------------------\n",
      "| o |   |   |   |   |   | o | \n",
      "------------------------------\n",
      "|   | o |   |   |   | o |   | \n",
      "------------------------------\n",
      "|   |   |   |   | o |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "| o |   |   |   | x | x | x | \n",
      "------------------------------\n",
      "( 6.0   6.0   5.0   6.0 )\n",
      "------------------------------\n",
      "| o |   |   |   |   |   | o | \n",
      "------------------------------\n",
      "|   | o |   |   |   | o |   | \n",
      "------------------------------\n",
      "|   |   |   |   | o |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   | x | \n",
      "------------------------------\n",
      "| o |   |   |   | x | x | x | \n",
      "------------------------------\n",
      "original row, col, target row, col\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "( 2   4   3   4 )\n",
      "------------------------------\n",
      "| o |   |   |   |   |   | o | \n",
      "------------------------------\n",
      "|   | o |   |   |   | o |   | \n",
      "------------------------------\n",
      "|   |   |   |   | o |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   | o |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   | x | \n",
      "------------------------------\n",
      "| o |   |   |   | x | x | x | \n",
      "------------------------------\n",
      "( 6.0   6.0   5.0   5.0 )\n",
      "------------------------------\n",
      "| o |   |   |   |   |   | o | \n",
      "------------------------------\n",
      "|   | o |   |   |   | o |   | \n",
      "------------------------------\n",
      "|   |   |   |   | o |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   | o |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   | x | x | \n",
      "------------------------------\n",
      "| o |   |   |   | x | x | x | \n",
      "------------------------------\n",
      "original row, col, target row, col\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "( 3   4   5   4 )\n",
      "------------------------------\n",
      "| o |   |   |   |   |   | o | \n",
      "------------------------------\n",
      "|   | o |   |   |   | o |   | \n",
      "------------------------------\n",
      "|   |   |   |   | o |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   | o | o | x | \n",
      "------------------------------\n",
      "| o |   |   |   | o | o | x | \n",
      "------------------------------\n",
      "( 6.0   6.0   4.0   6.0 )\n",
      "------------------------------\n",
      "| o |   |   |   |   |   | o | \n",
      "------------------------------\n",
      "|   | o |   |   |   | o |   | \n",
      "------------------------------\n",
      "|   |   |   |   | o |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   | x | \n",
      "------------------------------\n",
      "|   |   |   |   | o | x | x | \n",
      "------------------------------\n",
      "| o |   |   |   | o | o |   | \n",
      "------------------------------\n",
      "original row, col, target row, col\n",
      "6\n",
      "5\n",
      "4\n",
      "5\n",
      "( 6   5   4   5 )\n",
      "------------------------------\n",
      "| o |   |   |   |   |   | o | \n",
      "------------------------------\n",
      "|   | o |   |   |   | o |   | \n",
      "------------------------------\n",
      "|   |   |   |   | o |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "------------------------------\n",
      "|   |   |   |   |   | o | o | \n",
      "------------------------------\n",
      "|   |   |   |   | o | o | o | \n",
      "------------------------------\n",
      "| o |   |   |   | o |   |   | \n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f1011a14bb7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mjiyoon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mkapo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjiyoon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdora\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mkapo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-eb7d43228d0d>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misEnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"player\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"win\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0maction2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0maction2\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcantmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-efd752a38f4e>\u001b[0m in \u001b[0;36mgetAction\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mavq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mavq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \"\"\"\n\u001b[0;32m-> 1186\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "dora = Player(False,-1)\n",
    "dora.load(\"./model/model10000\")\n",
    "jiyoon = Player(True,1)\n",
    "kapo = contest(jiyoon,dora)\n",
    "kapo.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Charm_Cracker.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
